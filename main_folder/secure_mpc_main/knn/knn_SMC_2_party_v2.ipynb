{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from: https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
    "# github: https://github.com/madhug-nadig/Machine-Learning-Algorithms-from-Scratch/blob/master/K%20Means%20Clustering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from numpy.linalg import inv\n",
    "from scipy.interpolate import lagrange\n",
    "import random\n",
    "import os\n",
    "os.chdir(\"c:\\\\Users\\\\swart\\\\Desktop\\\\secure-mpc-main\\\\secure_mpc_main\")\n",
    "from network import NetworkNode, NetworkShare, merge, reconstruct\n",
    "from smpc_secrets import ShamirSecretSharing, AdditiveSecretSharing, Vandermonde, P, RandPoly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get iris dataset\n",
    "X_class,y_class = load_iris().data, load_iris().target\n",
    "\n",
    "# we just want binary classification\n",
    "X_class = X_class[:100]\n",
    "y_class = y_class[:100]\n",
    "\n",
    "X_class,y_class = shuffle(X_class, y_class, random_state=20)\n",
    "\n",
    "x_df = pd.DataFrame(X_class)\n",
    "y_df = pd.DataFrame(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data for alice, bob, server\n",
    "X_class_server, y_class_server = X_class[:90], y_class[:90]\n",
    "X_class_alice, y_class_alice = X_class[90:95], y_class[90:95]\n",
    "X_class_bob, y_class_bob = X_class[95:100], y_class[95:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "# each row is the set of feataures for a node\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secure_euclidean_distance(data1, data2):\n",
    "    node1 = NetworkShare(\"Node1\", node_id=1, k=3)\n",
    "    node2 = NetworkShare(\"Node2\", node_id=2, k=3)\n",
    "    server = NetworkNode(\"Server\", node_id=3, k=3)\n",
    "\n",
    "    node1_shares = node1.create_shares(data=data1)\n",
    "    node2_shares = node2.create_shares(data=data2)\n",
    "    # server_shares = server.create_shares([0]*len(data1))\n",
    "\n",
    "    print(node1_shares, node2_shares)\n",
    "    \n",
    "    node1_received_from_node2 = node2.get_shares_for(node_id=1, share_type=\"f\")\n",
    "    # node1_received_from_server = server.get_shares_for(node_id=1, share_type=\"f\")\n",
    "    node2_received_from_node1 = node1.get_shares_for(node_id=2, share_type=\"f\") \n",
    "    # node2_received_from_server = server.get_shares_for(node_id=2, share_type=\"f\")\n",
    "    server_received_from_node1 = node1.get_shares_for(node_id=3, share_type=\"f\")\n",
    "    server_received_from_node2 = node2.get_shares_for(node_id=3, share_type=\"f\")\n",
    "\n",
    "    # node1_merged = node1.merge_shares(shares=[node1_received_from_node2, node1_received_from_server], by=merge)\n",
    "    # node2_merged = node2.merge_shares(shares=[node2_received_from_node1, node2_received_from_server], by=merge)   \n",
    "    node1_merged = node1.merge_shares(shares=node1_received_from_node2, by=merge)\n",
    "    node2_merged = node2.merge_shares(shares=node2_received_from_node1, by=merge)   \n",
    "    server_merged = node2.merge_shares_with(shares=[server_received_from_node1, server_received_from_node2], by=merge)  \n",
    "\n",
    "    print(node1_merged, node2_merged, server_merged) \n",
    "\n",
    "    distance = reconstruct([node1_merged, node2_merged, server_merged])\n",
    "    print(distance)\n",
    "\n",
    "    return np.sqrt(abs(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(X_train, y_train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor i in range(len(X_train)):\n",
    "\t\tdist = secure_euclidean_distance(X_train[i], test_row)\n",
    "\t\tdistances.append((X_train[i], dist, y_train[i]))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append([distances[i][0], distances[i][2]])\n",
    "\treturn neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(X_train, y_train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors(X_train, y_train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_functions(features_arr):\n",
    "    all_functions = []\n",
    "    for feature in range(len(features_arr)):\n",
    "        func = RandPoly(name=f\"f{feature}\", n=1, \n",
    "                        R=[(i,x) for i, x in enumerate(list(\n",
    "            [features_arr[feature],random.randint(2,250)]))]).poly\n",
    "        all_functions.append(func)\n",
    "    return all_functions\n",
    "\n",
    "def generate_shares(func_array, node_id):\n",
    "    shares = []\n",
    "    for func in func_array:\n",
    "        shares.append(func(node_id))\n",
    "    return shares\n",
    "\n",
    "def get_feature_distances(arr1, arr2):\n",
    "    distances = []\n",
    "    for feature_a, feature_b in zip(arr1, arr2):\n",
    "        dist = (feature_a-feature_b)**2\n",
    "        distances.append(dist)\n",
    "    return distances\n",
    "\n",
    "def sum_distances(arr):\n",
    "    return sum(arr)\n",
    "\n",
    "def reconstruct(shares):\n",
    "    x = np.arange(1, len(shares) + 1)\n",
    "    y = shares\n",
    "    f = lagrange(x, y)\n",
    "    return f(0)\n",
    "    \n",
    "def simplified_calc(alice_data, bob_data):\n",
    "    # Alice's functions\n",
    "    assert len(alice_data) == len(bob_data), \"feature length mismatch!\"\n",
    "\n",
    "    # get private functions\n",
    "    alice_functions = generate_functions(alice_data)\n",
    "    bob_functions = generate_functions(bob_data)\n",
    "\n",
    "    # get shares\n",
    "    alice_personal_shares = generate_shares(alice_functions, 1)\n",
    "    alice_from_bob = generate_shares(bob_functions, 1)\n",
    "\n",
    "    bob_personal_shares = generate_shares(bob_functions, 2)\n",
    "    bob_from_alice = generate_shares(alice_functions, 2)\n",
    "\n",
    "    server_from_alice = generate_shares(alice_functions, 3)\n",
    "    server_from_bob = generate_shares(bob_functions, 3)\n",
    "\n",
    "    # compute distance for each feature\n",
    "    alice_distances = get_feature_distances(alice_personal_shares, alice_from_bob)\n",
    "    bob_distances = get_feature_distances(bob_personal_shares, bob_from_alice)\n",
    "    server_distances = get_feature_distances(server_from_alice, server_from_bob)\n",
    "\n",
    "    # get sum of distances\n",
    "    alice_sum = sum_distances(alice_distances)\n",
    "    bob_sum = sum_distances(bob_distances)\n",
    "    server_sum = sum_distances(server_distances)\n",
    "\n",
    "    print(alice_sum, bob_sum, server_sum)\n",
    "\n",
    "\n",
    "    dist_squared = reconstruct([alice_sum, bob_sum, server_sum])\n",
    "\n",
    "    alice_bob_distance = np.sqrt(dist_squared)\n",
    "\n",
    "    return alice_bob_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular calc:  4.242640687119285 \n",
      "\n",
      "5641 23434 53397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.242640687119285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,0]\n",
    "b = [3,3]\n",
    "\n",
    "print(\"regular calc: \", euclidean_distance(a,b), \"\\n\")\n",
    "simplified_calc(a,b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78a287c5d96b6319afb8ff820d73699c9ea67f71e25ce8473899e0e8b85a2ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
